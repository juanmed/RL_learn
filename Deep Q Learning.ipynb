{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0MDD8JuVVAw"
      },
      "source": [
        "## Reinforcement Learning Tutorial -2: DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3uMs5tkVVA0"
      },
      "source": [
        "### Author: MD Muhaimin Rahman\n",
        "contact: sezan92[at]gmail[dot]com\n",
        "\n",
        "### updated by juanmed on 2022.01.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgCbSwKXVVA3"
      },
      "source": [
        "In the last tutorial, I tried to explain Q-learning algorithm. The biggest problem with Q-learning is that,it only takes discrete inputs and outputs discrete values. In the Mountain Car problem, we solved this issue by discretizing states which are actually continuous. But this can't be done always. Specially when the states are multidimensional states or images. Deep learning comes here to solve this problem!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCnibaDXVVA4"
      },
      "source": [
        "For example breakout game by atari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFrpz2_uVVA5"
      },
      "source": [
        "![](https://github.com/sezan92/RLTutorialKeras/blob/master/English/RL%20Tutorial%202/Atari-breakout.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyeNWli-VVA6"
      },
      "source": [
        "Here , the states are the actual image itself! It is 210x160x3 size RGB numpy array. How will you make discrete for $Q learning$ ? Will that be efficient ? ***NO***! . DQN comes us to save us!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeW2a6SVVVA8"
      },
      "source": [
        "## Intuition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LySelEcVVA8"
      },
      "source": [
        "### Deep Q Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfQMXZBdVVA9"
      },
      "source": [
        "Q learning is a lookup table problem. i.e. You have the state , you just look at the table and see which action gives you best $Q$ value! That's it. But for continuous state - as mentioned above- you cannot make a lookup table! You need something like a regression model! Which will give you the Q values for given state and action! And the best regression model would be, Deep Neural Network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9swOf249VVA-"
      },
      "source": [
        "So, we will replace the Q table explained in the last tutorial with a Neural Network. i.e. some thing like the following picture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNm7uq_OVVA_"
      },
      "source": [
        "![](https://github.com/sezan92/RLTutorialKeras/blob/master/English/RL%20Tutorial%202/Q2DQN.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQ3QTeLmVVA_"
      },
      "source": [
        "***But there is one little problem!***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MqWcyR_VVBA"
      },
      "source": [
        "In our mountain car problem, we have three discrete actions. $0,1 & 2$ . Using the above architecture, we will have to calculate $Q$ value for each action . Because , you need to take the action with best $Q$ value. To get the action of the best $Q$ value, you need to know the $Q(state,action)$ for each state! So in our case, we will have to run same feed forward process three times!"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "NRESTekYVVBA"
      },
      "source": [
        "action_list =[0,1,2]\n",
        "Q1 = model.predict(state,action_list[0])\n",
        "Q2 = model.predict(state,action_list[1])\n",
        "Q3 = model.predict(state,action_list[2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "We2G5hoNVVBA"
      },
      "source": [
        "What if we have more 100 actions ? Will we feed forward 100 times! It is a bit inefficient!! Instead, we will use the following architecture."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzr_Y4A2VVBA"
      },
      "source": [
        "![](https://github.com/sezan92/RLTutorialKeras/blob/master/English/RL%20Tutorial%202/NewDQN.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29FHUiLuVVBA"
      },
      "source": [
        "Meaning, our output layer will calculate $Q$ value for each action. As a result we can calculate Q values in one single forward pass each step! And then we will choose the action with maximum value"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "VbzArMepVVBB"
      },
      "source": [
        "action = np.argmax(Q(state))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LjZW5wyVVBB"
      },
      "source": [
        "#### Bellman Update Equation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CeHIIJRVVBD"
      },
      "source": [
        "In the Original Equation, the bellman update equation is \n",
        "\\begin{equation}\n",
        "Q(s_t,a) = Q(s_t,a) + \\alpha (Q'(s_{t+1},a)-Q(s_t,a))\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwRRTIeMVVBE"
      },
      "source": [
        "For DQN, we will use similar equation, using Gradient descent\n",
        "\\begin{equation}\n",
        "\\theta_Q \\gets \\theta_Q - \\alpha \\frac{\\partial}{\\partial \\theta}(Q'(s_{t+1},a)-Q(s_t,a))^2\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ArF5FbbVVBE"
      },
      "source": [
        "If you are intelligent enough, then you may ask , why there is a squareed part in the gradient descent equation but not in the actual bellman update equation? The reason might be, Mean squared errors are more sensitive to sudden spikes in the target data, which makes it most popular metric for regression models!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4Mo4UMSVVBF"
      },
      "source": [
        "### The Concept of Experience Replay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWu2C7H5VVBF"
      },
      "source": [
        "One of the problems in Reinforcment learning is relearning Problem. That is , suppose, in the course of trial and error, one state $s_t$ comes only once or twice, and never comes back. What will happen? There is a chance that the Agent will forget that experience after some time- like us! . So we need to make the agent keep some kind of track of that memory as well. This problem was solved in 1993- yes 26 years ago- by Long Ji lin. In his paper, ***Reinforcement Learning for Robots Using Neural Networks*** , he introduced the concept of Experience Replay. What he did was, he initialized a buffer of a certain size . He stored the experiences of the agent, i.e. state $s_t$, action $a$,next state $s_{t+1}$, reward $r$ . Before training the agent, he you just sample randomly from the buffer . It also helps randomizing the data , which in turn, helps to converge the model faster, as mentioned by Yoshua Bengio in his paper ***Practical Recommendations for Gradient-Based Training of Deep\n",
        "Architectures***,2012 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woeNjfQsVVBF"
      },
      "source": [
        "### The concept of $\\epsilon$-greedy Policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zj5pqnt4VVBG"
      },
      "source": [
        "In the beginning of training, we will have to explore random actions. Because we dont know the value of each action for each state. So we will take some random actions. We will evaluate those actions and see which random action gives us the most rewards. We will try to increase those actions. It means, at first you just ***explore*** different actions , the more you take actions the less you explore and more use your previouse experience to guide you-known as ***exploit***.  This thing can be done using a technique -with another freaking out name- $\\epsilon$-greedy policy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq9sVtRVVVBG"
      },
      "source": [
        "The big idea is that, we will select a value of $\\epsilon$ , suppose $0.9$. Then we will generate a random floating point number . If the generated number is greater than $\\epsilon$ we will take action according to the DQN, otherwise a random action. After each episode , we will decrease the value of $\\epsilon$ . As a result , in the last episodes, the agent will take actions according to DQN model, not the random actions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "at87bYWJVVBG"
      },
      "source": [
        "- Set $\\epsilon$\n",
        "- Generate random number $n_{rand}$\n",
        "- if $n_{rand} < \\epsilon$ ***do***\n",
        "- - take random action\n",
        "- else ***do***\n",
        "- - take action according to DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLUkDM9gVVBG"
      },
      "source": [
        "### Coding!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRoktdBMVVBG"
      },
      "source": [
        "Okay, let's start the most juicy part!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY6Mzyd3VVBH"
      },
      "source": [
        "***Importing Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fW9aVjrYVVBH"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "import random\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQsVUua7VVBI"
      },
      "source": [
        "***Initialization of Environment***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MNjHbe28VVBI"
      },
      "outputs": [],
      "source": [
        "env = gym.make('MountainCar-v0')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuhRdi_pVVBJ"
      },
      "source": [
        "***Hyper parameters***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZ7tZ_BvVVBK"
      },
      "source": [
        "- ```action_size``` number of actions\n",
        "- ```actions``` the actions list\n",
        "- ```gamma``` discount factor $\\gamma$\n",
        "- ```lr``` learning rate $\\alpha$\n",
        "- ```num_episodes``` number of episodes\n",
        "- ```epsilon``` epsilon , to choose random actions for epsilon greedy policy \n",
        "- ```epsilon_decay``` epsilon decay rate\n",
        "- ```batch_size``` batch size for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "HffxpNvwVVBK"
      },
      "outputs": [],
      "source": [
        "action_list = [0,1,2]\n",
        "gamma =0.45\n",
        "lr =0.001\n",
        "num_episodes =1000\n",
        "epsilon =1\n",
        "epsilon_decay =0.995\n",
        "memory_size =1000\n",
        "batch_size=100\n",
        "show=False\n",
        "action_size=env.action_space.n\n",
        "state_size=env.observation_space.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vL-ZoWMxVVBL"
      },
      "outputs": [],
      "source": [
        "factor=[1,100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBrogM55VVBL"
      },
      "source": [
        "Initializing Replay buffer for ***Experience Replay***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgULcELZVVBL"
      },
      "source": [
        "- ```memory``` a deque -which is a special type of list with limited memory- the replay buffer\n",
        "- ```s``` current state\n",
        "- ```a``` action\n",
        "- ```new_s``` new state\n",
        "- ```r``` reward\n",
        "- ```d``` terminal\n",
        "- ```experience``` tuple of state,reward,action,next state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9vg3TLmVVBL"
      },
      "source": [
        "***Psuedocode*** for experience replay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anmz345wVVBL"
      },
      "source": [
        "- get initial state $s$\n",
        "- for each iteration do\n",
        "- - take a random action $a$\n",
        "- - get next state $s_{next}$, reward $r$, terminal $d$ \n",
        "- - $s \\gets s_{next}$\n",
        "- - if environment is terminated do\n",
        "- - - reward $\\gets$ -100\n",
        "- - - reset environment\n",
        "- - - add state,reward,action,next state into replay buffer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UKokuNYMVVBL"
      },
      "outputs": [],
      "source": [
        "memory=deque(maxlen=memory_size)\n",
        "s=env.reset()\n",
        "s = s.reshape((1,-1))\n",
        "s = s*factor\n",
        "for _ in range(memory_size):\n",
        "    a=env.action_space.sample()\n",
        "    new_s,r,d,_ =env.step(a)\n",
        "    new_s = new_s.reshape((1,-1))\n",
        "    new_s = new_s*factor\n",
        "    if show:\n",
        "        env.render()\n",
        "    if d:\n",
        "        r=-100\n",
        "        experience =(s,r,a,new_s,d)\n",
        "        s=env.reset()\n",
        "        s = s.reshape((1,-1))\n",
        "    else:    \n",
        "        experience =(s,r,a,new_s,d)\n",
        "    memory.append(experience)\n",
        "    s = new_s\n",
        "env.close()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y104OwMKVVBL"
      },
      "source": [
        "***Model Definition***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ks53p1MWVVBM"
      },
      "source": [
        "Here , I have defined the model as a simple MLP neural network with 2 hidden layers of 100 nodes with ```relu``` activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ziquiXzhVVBM",
        "outputId": "4e7fe7a5-1bd6-4a0d-ff0d-e6430d2f25e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 1, 100)            300       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1, 100)            10100     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1, 3)              303       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10,703\n",
            "Trainable params: 10,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(100,activation='relu',input_shape=(1,state_size)))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(action_size,activation='linear'))\n",
        "model.compile(loss='mse',optimizer=Adam(lr=lr),)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Ki59K36VVBN"
      },
      "source": [
        "Here ,\n",
        "- ```ep_list``` list of episodes\n",
        "- ```reward_list``` list of rewards\n",
        "- ```total_rewards``` totatl reward"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui-LO6iuVVBN"
      },
      "source": [
        "***Psuedocode***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLiUHU2tVVBO"
      },
      "source": [
        "- for each episode do\n",
        "- - get initial state $s$\n",
        "- -  $rewards_{total} \\gets 0 $\n",
        "- - set terminal $d$ to false \n",
        "- - for each step do\n",
        "- - - choose action based on epsilon greedy policy\n",
        "- - - get next state $s_{next}$, reward $r$, terminal $d$ doing the action\n",
        "- - - $rewards_{total} \\gets rewards_{total}+r$\n",
        "- - - if $d$ is $True $ \n",
        "- - - - if $rewards_{total}<-199$ \n",
        "- - - - - then give punishment $r \\gets -100$\n",
        "- - - - - break \n",
        "- - - $s \\gets s_{next}$\n",
        "- - take random samples of $s,r,a,s_{next}$ from replay buffer\n",
        "- - get $Q(s_{next})$ \n",
        "- - $Q_{target} \\gets r+\\gamma max(Q(s_{next})) $\n",
        "- - $loss \\gets \\frac{1}{N}\\sum(Q_{target}-Q(s))^2$\n",
        "- - train the network using this loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VMzcRMR8VVBO",
        "outputId": "3376e6b6-1c34-483b-ee78-5d8a079fb282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode 0, Failed! Reward -200\n",
            "Episode 1, Failed! Reward -200\n",
            "Episode 2, Failed! Reward -200\n",
            "Episode 3, Failed! Reward -200\n",
            "Episode 4, Failed! Reward -200\n",
            "Episode 5, Failed! Reward -200\n",
            "Episode 6, Failed! Reward -200\n",
            "Episode 7, Failed! Reward -200\n",
            "Episode 8, Failed! Reward -200\n",
            "Episode 9, Failed! Reward -200\n",
            "Episode 10, Failed! Reward -200\n",
            "Episode 11, Failed! Reward -200\n",
            "Episode 12, Failed! Reward -200\n",
            "Episode 13, Failed! Reward -200\n",
            "Episode 14, Failed! Reward -200\n",
            "Episode 15, Failed! Reward -200\n",
            "Episode 16, Failed! Reward -200\n",
            "Episode 17, Failed! Reward -200\n",
            "Episode 18, Failed! Reward -200\n",
            "Episode 19, Failed! Reward -200\n",
            "Episode 20, Failed! Reward -200\n",
            "Episode 21, Failed! Reward -200\n",
            "Episode 22, Failed! Reward -200\n",
            "Episode 23, Failed! Reward -200\n",
            "Episode 24, Failed! Reward -200\n",
            "Episode 25, Failed! Reward -200\n",
            "Episode 26, Failed! Reward -200\n",
            "Episode 27, Failed! Reward -200\n",
            "Episode 28, Failed! Reward -200\n",
            "Episode 29, Failed! Reward -200\n",
            "Episode 30, Failed! Reward -200\n",
            "Episode 31, Failed! Reward -200\n",
            "Episode 32, Failed! Reward -200\n",
            "Episode 33, Failed! Reward -200\n",
            "Episode 34, Failed! Reward -200\n",
            "Episode 35, Failed! Reward -200\n",
            "Episode 36, Failed! Reward -200\n",
            "Episode 37, Failed! Reward -200\n",
            "Episode 38, Failed! Reward -200\n",
            "Episode 39, Failed! Reward -200\n",
            "Episode 40, Failed! Reward -200\n",
            "Episode 41, Failed! Reward -200\n",
            "Episode 42, Failed! Reward -200\n",
            "Episode 43, Failed! Reward -200\n",
            "Episode 44, Failed! Reward -200\n",
            "Episode 45, Failed! Reward -200\n",
            "Episode 46, Failed! Reward -200\n",
            "Episode 47, Failed! Reward -200\n",
            "Episode 48, Failed! Reward -200\n",
            "Episode 49, Failed! Reward -200\n",
            "Episode 50, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 51, Failed! Reward -200\n",
            "Episode 52, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 53, Failed! Reward -200\n",
            "Episode 54, Failed! Reward -200\n",
            "Episode 55, Failed! Reward -200\n",
            "Episode 56, Failed! Reward -200\n",
            "Episode 57, Failed! Reward -200\n",
            "Episode 58, Failed! Reward -200\n",
            "Episode 59, Failed! Reward -200\n",
            "Episode 60, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 61, Failed! Reward -200\n",
            "Episode 62, Failed! Reward -200\n",
            "Episode 63, Failed! Reward -200\n",
            "Episode 64, Failed! Reward -200\n",
            "Episode 65, Failed! Reward -200\n",
            "Episode 66, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 67, Failed! Reward -200\n",
            "Episode 68, Failed! Reward -200\n",
            "Episode 69, Failed! Reward -200\n",
            "Episode 70, Failed! Reward -200\n",
            "Episode 71, Failed! Reward -200\n",
            "Episode 72, Failed! Reward -200\n",
            "Episode 73, Failed! Reward -200\n",
            "Episode 74, Failed! Reward -200\n",
            "Episode 75, Failed! Reward -200\n",
            "Episode 76, Failed! Reward -200\n",
            "Episode 77, Failed! Reward -200\n",
            "Episode 78, Failed! Reward -200\n",
            "Episode 79, Failed! Reward -200\n",
            "Episode 80, Failed! Reward -200\n",
            "Episode 81, Failed! Reward -200\n",
            "Episode 82, Failed! Reward -200\n",
            "Episode 83, Failed! Reward -200\n",
            "Episode 84, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 85, Failed! Reward -200\n",
            "Episode 86, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 87, Failed! Reward -200\n",
            "Episode 88, Failed! Reward -200\n",
            "Episode 89, Failed! Reward -200\n",
            "Episode 90, Failed! Reward -200\n",
            "Episode 91, Failed! Reward -200\n",
            "Episode 92, Failed! Reward -200\n",
            "Episode 93, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 94, Failed! Reward -200\n",
            "Episode 95, Failed! Reward -200\n",
            "Episode 96, Failed! Reward -200\n",
            "Episode 97, Failed! Reward -200\n",
            "Episode 98, Failed! Reward -200\n",
            "Episode 99, Failed! Reward -200\n",
            "Episode 100, Failed! Reward -200\n",
            "Episode 101, Failed! Reward -200\n",
            "Episode 102, Failed! Reward -200\n",
            "Episode 103, Failed! Reward -200\n",
            "Episode 104, Failed! Reward -200\n",
            "Episode 105, Failed! Reward -200\n",
            "Episode 106, Failed! Reward -200\n",
            "Episode 107, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 108, Failed! Reward -200\n",
            "Episode 109, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 110, Failed! Reward -200\n",
            "Episode 111, Failed! Reward -200\n",
            "Episode 112, Failed! Reward -200\n",
            "Episode 113, Failed! Reward -200\n",
            "Episode 114, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 115, Failed! Reward -200\n",
            "Episode 116, Failed! Reward -200\n",
            "Episode 117, Failed! Reward -200\n",
            "Episode 118, Failed! Reward -200\n",
            "Episode 119, Failed! Reward -200\n",
            "Episode 120, Failed! Reward -200\n",
            "Episode 121, Failed! Reward -200\n",
            "Episode 122, Failed! Reward -200\n",
            "Episode 123, Failed! Reward -200\n",
            "Episode 124, Failed! Reward -200\n",
            "Episode 125, Failed! Reward -200\n",
            "Episode 126, Failed! Reward -200\n",
            "Episode 127, Failed! Reward -200\n",
            "Episode 128, Failed! Reward -200\n",
            "Episode 129, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 130, Failed! Reward -200\n",
            "Episode 131, Failed! Reward -200\n",
            "Episode 132, Failed! Reward -200\n",
            "Episode 133, Failed! Reward -200\n",
            "Episode 134, Failed! Reward -200\n",
            "Episode 135, Failed! Reward -200\n",
            "Episode 136, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 137, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 138, Failed! Reward -200\n",
            "Episode 139, Failed! Reward -200\n",
            "Episode 140, Failed! Reward -200\n",
            "Episode 141, Failed! Reward -200\n",
            "Episode 142, Failed! Reward -200\n",
            "Episode 143, Failed! Reward -200\n",
            "Episode 144, Failed! Reward -200\n",
            "Episode 145, Failed! Reward -200\n",
            "Episode 146, Failed! Reward -200\n",
            "Episode 147, Failed! Reward -200\n",
            "Episode 148, Failed! Reward -200\n",
            "Episode 149, Failed! Reward -200\n",
            "Episode 150, Failed! Reward -200\n",
            "Episode 151, Failed! Reward -200\n",
            "Episode 152, Failed! Reward -200\n",
            "Episode 153, Failed! Reward -200\n",
            "Episode 154, Failed! Reward -200\n",
            "Episode 155, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 156, Failed! Reward -200\n",
            "Episode 157, Failed! Reward -200\n",
            "Episode 158, Failed! Reward -200\n",
            "Episode 159, Failed! Reward -200\n",
            "Episode 160, Failed! Reward -200\n",
            "Episode 161, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 162, Failed! Reward -200\n",
            "Episode 163, Failed! Reward -200\n",
            "Episode 164, Failed! Reward -200\n",
            "Episode 165, Failed! Reward -200\n",
            "Episode 166, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 167, Failed! Reward -200\n",
            "Episode 168, Failed! Reward -200\n",
            "Episode 169, Failed! Reward -200\n",
            "Episode 170, Failed! Reward -200\n",
            "Episode 171, Failed! Reward -200\n",
            "Episode 172, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 173, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 174, Failed! Reward -200\n",
            "Episode 175, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 176, Failed! Reward -200\n",
            "Episode 177, Failed! Reward -200\n",
            "Episode 178, Failed! Reward -200\n",
            "Episode 179, Failed! Reward -200\n",
            "Episode 180, Failed! Reward -200\n",
            "Episode 181, Failed! Reward -200\n",
            "Episode 182, Failed! Reward -200\n",
            "Episode 183, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 184, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 185, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 186, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 187, Failed! Reward -200\n",
            "Episode 188, Failed! Reward -200\n",
            "Episode 189, Failed! Reward -200\n",
            "Episode 190, Failed! Reward -200\n",
            "Episode 191, Failed! Reward -200\n",
            "Episode 192, Failed! Reward -200\n",
            "Episode 193, Better! Reward -138\n",
            "Episode 194, Failed! Reward -200\n",
            "Episode 195, Failed! Reward -200\n",
            "Episode 196, Failed! Reward -200\n",
            "Episode 197, Failed! Reward -200\n",
            "Episode 198, Failed! Reward -200\n",
            "Episode 199, Failed! Reward -200\n",
            "Episode 200, Failed! Reward -200\n",
            "Episode 201, Failed! Reward -200\n",
            "Episode 202, Failed! Reward -200\n",
            "Episode 203, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 204, Failed! Reward -200\n",
            "Episode 205, Failed! Reward -200\n",
            "Episode 206, Failed! Reward -200\n",
            "Episode 207, Failed! Reward -200\n",
            "Episode 208, Failed! Reward -200\n",
            "Episode 209, Failed! Reward -200\n",
            "Episode 210, Failed! Reward -200\n",
            "Episode 211, Failed! Reward -200\n",
            "Episode 212, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 213, Failed! Reward -200\n",
            "Episode 214, Failed! Reward -200\n",
            "Episode 215, Failed! Reward -200\n",
            "Episode 216, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 217, Failed! Reward -200\n",
            "Episode 218, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 219, Failed! Reward -200\n",
            "Episode 220, Failed! Reward -200\n",
            "Episode 221, Failed! Reward -200\n",
            "Episode 222, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 223, Failed! Reward -200\n",
            "Episode 224, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 225, Failed! Reward -200\n",
            "Episode 226, Failed! Reward -200\n",
            "Episode 227, Failed! Reward -200\n",
            "Episode 228, Failed! Reward -200\n",
            "Episode 229, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 230, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 231, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 232, Failed! Reward -200\n",
            "Episode 233, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 234, Failed! Reward -200\n",
            "Episode 235, Failed! Reward -200\n",
            "Episode 236, Failed! Reward -200\n",
            "Episode 237, Failed! Reward -200\n",
            "Episode 238, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 239, Failed! Reward -200\n",
            "Episode 240, Failed! Reward -200\n",
            "Episode 241, Failed! Reward -200\n",
            "Episode 242, Failed! Reward -200\n",
            "Episode 243, Failed! Reward -200\n",
            "Episode 244, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 245, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 246, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 247, Failed! Reward -200\n",
            "Episode 248, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 249, Failed! Reward -200\n",
            "Episode 250, Failed! Reward -200\n",
            "Episode 251, Failed! Reward -200\n",
            "Episode 252, Failed! Reward -200\n",
            "Episode 253, Failed! Reward -200\n",
            "Episode 254, Failed! Reward -200\n",
            "Episode 255, Failed! Reward -200\n",
            "Episode 256, Better! Reward -175\n",
            "Episode 257, Better! Reward -178\n",
            "Episode 258, Better! Reward -171\n",
            "Episode 259, Better! Reward -168\n",
            "Episode 260, Better! Reward -166\n",
            "Episode 261, Better! Reward -168\n",
            "Episode 262, Passed! Reward -88\n",
            "Episode 263, Passed! Reward -91\n",
            "Episode 264, Better! Reward -179\n",
            "Episode 265, Better! Reward -165\n",
            "Episode 266, Passed! Reward -85\n",
            "Episode 267, Passed! Reward -89\n",
            "Episode 268, Better! Reward -120\n",
            "Episode 269, Better! Reward -122\n",
            "Episode 270, Better! Reward -123\n",
            "Episode 271, Better! Reward -119\n",
            "Episode 272, Better! Reward -122\n",
            "Episode 273, Better! Reward -122\n",
            "Episode 274, Better! Reward -119\n",
            "Episode 275, Better! Reward -123\n",
            "Episode 276, Better! Reward -120\n",
            "Episode 277, Better! Reward -122\n",
            "Episode 278, Better! Reward -168\n",
            "Episode 279, Passed! Reward -87\n",
            "Episode 280, Better! Reward -161\n",
            "Episode 281, Passed! Reward -98\n",
            "Episode 282, Better! Reward -163\n",
            "Episode 283, Better! Reward -164\n",
            "Episode 284, Passed! Reward -99\n",
            "Episode 285, Better! Reward -165\n",
            "Episode 286, Better! Reward -161\n",
            "Episode 287, Passed! Reward -96\n",
            "Episode 288, Passed! Reward -88\n",
            "Episode 289, Passed! Reward -91\n",
            "Episode 290, Passed! Reward -97\n",
            "Episode 291, Better! Reward -169\n",
            "Episode 292, Better! Reward -179\n",
            "Episode 293, Better! Reward -174\n",
            "Episode 294, Better! Reward -171\n",
            "Episode 295, Better! Reward -171\n",
            "Episode 296, Better! Reward -165\n",
            "Episode 297, Passed! Reward -96\n",
            "Episode 298, Better! Reward -166\n",
            "Episode 299, Better! Reward -177\n",
            "Episode 300, Better! Reward -166\n",
            "Episode 301, Better! Reward -169\n",
            "Episode 302, Passed! Reward -88\n",
            "Episode 303, Better! Reward -167\n",
            "Episode 304, Better! Reward -167\n",
            "Episode 305, Better! Reward -170\n",
            "Episode 306, Better! Reward -112\n",
            "Episode 307, Better! Reward -173\n",
            "Episode 308, Better! Reward -173\n",
            "Episode 309, Passed! Reward -91\n",
            "Episode 310, Better! Reward -175\n",
            "Episode 311, Better! Reward -177\n",
            "Episode 312, Passed! Reward -94\n",
            "Episode 313, Better! Reward -169\n",
            "Episode 314, Better! Reward -169\n",
            "Episode 315, Better! Reward -177\n",
            "Episode 316, Better! Reward -171\n",
            "Episode 317, Better! Reward -177\n",
            "Episode 318, Passed! Reward -91\n",
            "Episode 319, Better! Reward -117\n",
            "Episode 320, Better! Reward -178\n",
            "Episode 321, Better! Reward -179\n",
            "Episode 322, Better! Reward -180\n",
            "Episode 323, Better! Reward -116\n",
            "Episode 324, Better! Reward -174\n",
            "Episode 325, Passed! Reward -89\n",
            "Episode 326, Passed! Reward -94\n",
            "Episode 327, Passed! Reward -93\n",
            "Episode 328, Better! Reward -124\n",
            "Episode 329, Passed! Reward -92\n",
            "Episode 330, Better! Reward -183\n",
            "Episode 331, Passed! Reward -94\n",
            "Episode 332, Better! Reward -168\n",
            "Episode 333, Passed! Reward -98\n",
            "Episode 334, Better! Reward -167\n",
            "Episode 335, Better! Reward -170\n",
            "Episode 336, Better! Reward -169\n",
            "Episode 337, Passed! Reward -100\n",
            "Episode 338, Better! Reward -178\n",
            "Episode 339, Better! Reward -172\n",
            "Episode 340, Passed! Reward -94\n",
            "Episode 341, Better! Reward -174\n",
            "Episode 342, Better! Reward -177\n",
            "Episode 343, Better! Reward -181\n",
            "Episode 344, Failed! Reward -200\n",
            "Episode 345, Better! Reward -113\n",
            "Episode 346, Better! Reward -187\n",
            "Episode 347, Better! Reward -186\n",
            "Episode 348, Better! Reward -193\n",
            "Episode 349, Better! Reward -191\n",
            "Episode 350, Failed! Reward -200\n",
            "Episode 351, Failed! Reward -200\n",
            "Episode 352, Failed! Reward -200\n",
            "Episode 353, Failed! Reward -200\n",
            "Episode 354, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 355, Better! Reward -189\n",
            "Episode 356, Better! Reward -189\n",
            "Episode 357, Better! Reward -180\n",
            "Episode 358, Better! Reward -112\n",
            "Episode 359, Passed! Reward -102\n",
            "Episode 360, Passed! Reward -94\n",
            "Episode 361, Better! Reward -182\n",
            "Episode 362, Better! Reward -179\n",
            "Episode 363, Passed! Reward -107\n",
            "Episode 364, Better! Reward -179\n",
            "Episode 365, Passed! Reward -98\n",
            "Episode 366, Better! Reward -182\n",
            "Episode 367, Passed! Reward -97\n",
            "Episode 368, Better! Reward -188\n",
            "Episode 369, Better! Reward -181\n",
            "Episode 370, Better! Reward -186\n",
            "Episode 371, Passed! Reward -98\n",
            "Episode 372, Failed! Reward -200\n",
            "Episode 373, Better! Reward -187\n",
            "Episode 374, Better! Reward -181\n",
            "Episode 375, Better! Reward -185\n",
            "Episode 376, Better! Reward -188\n",
            "Episode 377, Better! Reward -179\n",
            "Episode 378, Failed! Reward -200\n",
            "Episode 379, Better! Reward -113\n",
            "Episode 380, Failed! Reward -200\n",
            "Episode 381, Failed! Reward -200\n",
            "Episode 382, Better! Reward -193\n",
            "Episode 383, Better! Reward -190\n",
            "Episode 384, Failed! Reward -200\n",
            "Episode 385, Failed! Reward -200\n",
            "Episode 386, Better! Reward -120\n",
            "Episode 387, Better! Reward -185\n",
            "Episode 388, Better! Reward -186\n",
            "Episode 389, Better! Reward -195\n",
            "Episode 390, Failed! Reward -200\n",
            "Episode 391, Failed! Reward -200\n",
            "Episode 392, Failed! Reward -200\n",
            "Episode 393, Failed! Reward -200\n",
            "Episode 394, Better! Reward -192\n",
            "Episode 395, Failed! Reward -200\n",
            "Episode 396, Better! Reward -179\n",
            "Episode 397, Better! Reward -130\n",
            "Episode 398, Better! Reward -155\n",
            "Episode 399, Failed! Reward -200\n",
            "Episode 400, Failed! Reward -200\n",
            "Episode 401, Better! Reward -168\n",
            "Episode 402, Better! Reward -174\n",
            "Episode 403, Better! Reward -121\n",
            "Episode 404, Passed! Reward -104\n",
            "Episode 405, Better! Reward -182\n",
            "Episode 406, Failed! Reward -200\n",
            "Episode 407, Better! Reward -181\n",
            "Episode 408, Better! Reward -182\n",
            "Episode 409, Passed! Reward -99\n",
            "Episode 410, Better! Reward -186\n",
            "Episode 411, Better! Reward -177\n",
            "Episode 412, Better! Reward -178\n",
            "Episode 413, Better! Reward -183\n",
            "Episode 414, Passed! Reward -110\n",
            "Episode 415, Better! Reward -180\n",
            "Episode 416, Better! Reward -182\n",
            "Episode 417, Failed! Reward -200\n",
            "Episode 418, Passed! Reward -98\n",
            "Episode 419, Better! Reward -178\n",
            "Episode 420, Better! Reward -179\n",
            "Episode 421, Passed! Reward -97\n",
            "Episode 422, Better! Reward -170\n",
            "Episode 423, Better! Reward -168\n",
            "Episode 424, Better! Reward -174\n",
            "Episode 425, Passed! Reward -97\n",
            "Episode 426, Better! Reward -174\n",
            "Episode 427, Better! Reward -169\n",
            "Episode 428, Better! Reward -120\n",
            "Episode 429, Better! Reward -128\n",
            "Episode 430, Better! Reward -172\n",
            "Episode 431, Better! Reward -169\n",
            "Episode 432, Better! Reward -192\n",
            "Episode 433, Better! Reward -171\n",
            "Episode 434, Better! Reward -171\n",
            "Episode 435, Better! Reward -176\n",
            "Episode 436, Better! Reward -172\n",
            "Episode 437, Better! Reward -175\n",
            "Episode 438, Better! Reward -130\n",
            "Episode 439, Better! Reward -142\n",
            "Episode 440, Better! Reward -112\n",
            "Episode 441, Passed! Reward -102\n",
            "Episode 442, Better! Reward -172\n",
            "Episode 443, Passed! Reward -97\n",
            "Episode 444, Better! Reward -173\n",
            "Episode 445, Better! Reward -177\n",
            "Episode 446, Passed! Reward -93\n",
            "Episode 447, Passed! Reward -93\n",
            "Episode 448, Better! Reward -177\n",
            "Episode 449, Better! Reward -175\n",
            "Episode 450, Passed! Reward -90\n",
            "Episode 451, Better! Reward -126\n",
            "Episode 452, Better! Reward -127\n",
            "Episode 453, Passed! Reward -90\n",
            "Episode 454, Better! Reward -129\n",
            "Episode 455, Better! Reward -127\n",
            "Episode 456, Passed! Reward -87\n",
            "Episode 457, Better! Reward -130\n",
            "Episode 458, Better! Reward -171\n",
            "Episode 459, Passed! Reward -91\n",
            "Episode 460, Better! Reward -169\n",
            "Episode 461, Failed! Reward -200\n",
            "Episode 462, Passed! Reward -90\n",
            "Episode 463, Better! Reward -173\n",
            "Episode 464, Better! Reward -176\n",
            "Episode 465, Better! Reward -171\n",
            "Episode 466, Better! Reward -170\n",
            "Episode 467, Better! Reward -172\n",
            "Episode 468, Passed! Reward -110\n",
            "Episode 469, Failed! Reward -200\n",
            "Episode 470, Failed! Reward -200\n",
            "Episode 471, Failed! Reward -200\n",
            "Episode 472, Failed! Reward -200\n",
            "Episode 473, Failed! Reward -200\n",
            "Episode 474, Failed! Reward -200\n",
            "Episode 475, Failed! Reward -200\n",
            "Episode 476, Failed! Reward -200\n",
            "Episode 477, Better! Reward -146\n",
            "Episode 478, Failed! Reward -200\n",
            "Episode 479, Failed! Reward -200\n",
            "Episode 480, Failed! Reward -200\n",
            "Episode 481, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 482, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 483, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 484, Failed! Reward -200\n",
            "Episode 485, Failed! Reward -200\n",
            "Episode 486, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 487, Failed! Reward -200\n",
            "Episode 488, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 489, Failed! Reward -200\n",
            "Episode 490, Failed! Reward -200\n",
            "Episode 491, Failed! Reward -200\n",
            "Episode 492, Better! Reward -187\n",
            "Episode 493, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 494, Failed! Reward -200\n",
            "Episode 495, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 496, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 497, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 498, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 499, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 500, Failed! Reward -200\n",
            "Episode 501, Failed! Reward -200\n",
            "Episode 502, Failed! Reward -200\n",
            "Episode 503, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 504, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 505, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 506, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 507, Failed! Reward -200\n",
            "Episode 508, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 509, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 510, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 511, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 512, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 513, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 514, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 515, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 516, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 517, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 518, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 519, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 520, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 521, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 522, Failed! Reward -200\n",
            "Episode 523, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 524, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 525, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 526, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 527, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 528, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 529, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 530, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 531, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 532, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 533, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 534, Failed! Reward -200\n",
            "Episode 535, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 536, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 537, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 538, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 539, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 540, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 541, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 542, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 543, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 544, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 545, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 546, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 547, Failed! Reward -200\n",
            "Episode 548, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 549, Failed! Reward -200\n",
            "Episode 550, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 551, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 552, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 553, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 554, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 555, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 556, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 557, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 558, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 559, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 560, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 561, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 562, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 563, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 564, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 565, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 566, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 567, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 568, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 569, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 570, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 571, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 572, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 573, Failed! Reward -200\n",
            "Episode 574, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 575, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 576, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 577, Failed! Reward -200\n",
            "Episode 578, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 579, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 580, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 581, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 582, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 583, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 584, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 585, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 586, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 587, Failed! Reward -200\n",
            "Episode 588, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 589, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 590, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 591, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 592, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 593, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 594, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 595, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 596, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 597, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 598, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 599, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 600, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 601, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 602, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 603, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 604, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 605, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 606, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 607, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 608, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 609, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 610, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 611, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 612, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 613, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 614, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 615, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 616, Failed! Reward -200\n",
            "Episode 617, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 618, Failed! Reward -200\n",
            "Episode 619, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 620, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 621, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 622, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 623, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 624, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 625, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 626, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 627, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 628, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 629, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 630, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 631, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 632, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 633, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 634, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 635, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 636, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 637, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 638, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 639, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 640, Failed! Reward -200\n",
            "Episode 641, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 642, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 643, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 644, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 645, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 646, Failed! Reward -200\n",
            "Episode 647, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 648, Failed! Reward -200\n",
            "Episode 649, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 650, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 651, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 652, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 653, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 654, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 655, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 656, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 657, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 658, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 659, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n",
            "Episode 660, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 661, Failed! Reward -200\n",
            "cannot reshape array of size 200 into shape (1,3)\n",
            "Episode 662, Failed! Reward -200\n",
            "cannot reshape array of size 100 into shape (1,3)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-7c0c1f90479a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnew_s\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1766\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1767\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1768\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1770\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1403\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         warnings.warn(\"The `deterministic` argument has no effect unless the \"\n\u001b[1;32m   2003\u001b[0m                       \"`num_parallel_calls` argument is specified.\")\n\u001b[0;32m-> 2004\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m       return ParallelMapDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m   5457\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5458\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5459\u001b[0;31m         use_legacy_function=use_legacy_function)\n\u001b[0m\u001b[1;32m   5460\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_metadata_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5461\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   4531\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4533\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4534\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4535\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3243\u001b[0m     \"\"\"\n\u001b[1;32m   3244\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3245\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3246\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3247\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3208\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3209\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3210\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3211\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3556\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3557\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3558\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3400\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3401\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3402\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3403\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3404\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4508\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m   4509\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4510\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4511\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4512\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   4438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4439\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4440\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4442\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    694\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 464\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mpermutation\u001b[0;34m(_)\u001b[0m\n\u001b[1;32m    280\u001b[0m       \u001b[0;31m# than reusing the same range Tensor. (presumably because of buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;31m# forwarding.)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1094\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1096\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1097\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mrange\u001b[0;34m(start, limit, delta, dtype, name)\u001b[0m\n\u001b[1;32m   2081\u001b[0m       \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2083\u001b[0;31m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"limit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m       \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"delta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m    271\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 272\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    292\u001b[0m   \u001b[0mattrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdtype_value\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m   const_tensor = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m--> 294\u001b[0;31m       \"Const\", [], [dtype_value.type], attrs=attrs, name=name).outputs[0]\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    689\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    690\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3703\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3704\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3705\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3706\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3707\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2098\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2099\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1927\u001b[0m   \u001b[0;31m# Add attrs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1928\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1929\u001b[0;31m     \u001b[0mserialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1930\u001b[0m     \u001b[0;31m# TODO(skyewm): this creates and deletes a new TF_Status for every attr.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m     \u001b[0;31m# It might be worth creating a convenient way to re-use the same status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ep_list =[]\n",
        "reward_list =[] \n",
        "index=0 \n",
        "#oh = OneHotEncoder(3)\n",
        "ct = ColumnTransformer([('my_ohe', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "for ep in range(num_episodes):\n",
        "    s= env.reset()\n",
        "    s=s.reshape((1,-1))\n",
        "    s = s*factor\n",
        "    total_rewards =0\n",
        "    d = False\n",
        "    j = 0\n",
        "    for j in range(200):\n",
        "        if np.random.random()< epsilon:\n",
        "            a = np.random.randint(0,len(action_list))\n",
        "        else:\n",
        "            Q = model.predict(s.reshape(-1,s.shape[0],s.shape[1]))\n",
        "            a =np.argmax(Q)\n",
        "        new_s,r,d,_ = env.step(a)\n",
        "        new_s = new_s.reshape((1,-1))\n",
        "        new_s = new_s*factor\n",
        "        total_rewards=total_rewards+r\n",
        "        if show:\n",
        "            env.render()\n",
        "        if d:\n",
        "            if total_rewards<-199:\n",
        "                r =-100\n",
        "                experience = (s,r,a,new_s,d)\n",
        "                memory.append(experience)\n",
        "                print(\"Episode %d, Failed! Reward %d\"%(ep,total_rewards))\n",
        "            elif total_rewards<-110 and total_rewards>-199:\n",
        "                r=10\n",
        "                d=True\n",
        "                experience = (s,r,a,new_s,d)\n",
        "                memory.append(experience)\n",
        "                print(\"Episode %d, Better! Reward %d\"%(ep,total_rewards))\n",
        "            elif total_rewards>=-110:\n",
        "                r=100\n",
        "                experience = (s,r,a,new_s,d)\n",
        "                memory.append(experience)\n",
        "\n",
        "                print(\"Episode %d, Passed! Reward %d\"%(ep,total_rewards))\n",
        "            ep_list.append(ep)\n",
        "            reward_list.append(total_rewards)\n",
        "            break\n",
        "        \n",
        "        experience = (s,r,a,new_s,d)\n",
        "        memory.append(experience)\n",
        "        if j==199:\n",
        "            print(\"Reward %d after full episode\"%(total_rewards))\n",
        "            \n",
        "        s = new_s\n",
        "    batches=random.sample(memory,batch_size)\n",
        "    states= np.array([batch[0] for batch in batches])\n",
        "    rewards= np.array([batch[1] for batch in batches])\n",
        "    actions= np.array([batch[2] for batch in batches])\n",
        "    #actions=oh.fit_transform(actions.reshape(-1,1)).toarray()\n",
        "    actions = ct.fit_transform(actions.reshape(-1,1))\n",
        "    try:\n",
        "      actions = actions.reshape(-1,1,action_size)\n",
        "      new_states= np.array([batch[3] for batch in batches])\n",
        "      dones= np.array([batch[4] for batch in batches])\n",
        "      Qs =model.predict(states)\n",
        "      new_Qs = model.predict(new_states)\n",
        "      target_Qs=rewards.reshape(-1,1)+gamma*(np.max(new_Qs,axis=2)*(~dones.reshape(-1,1)))\n",
        "      Qs[actions==1]=target_Qs.reshape(-1,)\n",
        "      model.fit(states,Qs,verbose=0)\n",
        "      epsilon=epsilon*epsilon_decay\n",
        "    except Exception as e:\n",
        "      print(str(e))\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "YUqaOLjFVVBP",
        "outputId": "80b9fe4c-e75a-4fa0-d1d4-9ef5496b86fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Rewards')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(reward_list)\n",
        "plt.title(\"Rewards vs Episode\")\n",
        "plt.xlabel(\"Episodes\")\n",
        "plt.ylabel(\"Rewards\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiOT-LZWVVBQ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "Deep Q Learning.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}